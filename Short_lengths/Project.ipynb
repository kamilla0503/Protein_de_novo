{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdbfixer as pf\n",
    "from simtk.openmm.app import PDBFile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from htmd.ui import *\n",
    "from htmd import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from htmd.config import config\n",
    "config(viewer='webgl')\n",
    "\n",
    "\n",
    "from moleculekit.molecule import Molecule\n",
    "from moleculekit.tools.voxeldescriptors import getVoxelDescriptors, viewVoxelFeatures\n",
    "from moleculekit.tools.atomtyper import prepareProteinForAtomtyping\n",
    "from moleculekit.smallmol.smallmol import SmallMol\n",
    "from moleculekit.home import home\n",
    "import os \n",
    "\n",
    "from moleculekit.molecule import Molecule\n",
    "from openbabel import pybel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directiry =  Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"A   C   D   E   F   G   H   I   K   L   M   N   P   Q   R   S   T   V   W   Y\".split()\n",
    "s = np.array(s).reshape(-1, 1)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "encoded = enc.fit(s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "Nmax = 80 \n",
    "nchannels = 8\n",
    "\n",
    "for fn in Path(current_directiry).glob(\"*.pdb\"):\n",
    "    print(fn)\n",
    "    prot = Molecule(str(fn),validateElements=False)\n",
    "    \n",
    "    prot.filter(\"protein\")\n",
    "    #print(len(list(prot.sequence()[key[0]]) ))\n",
    "    #print(prot.sequence())\n",
    "    \n",
    "    key = list(prot.sequence() )    \n",
    "    seq = np.array( list(prot.sequence()[key[0]]) )\n",
    "    #print(len(seq), fn, seq.shape)\n",
    "    \n",
    "    if (len(seq)>Nmax):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        encoded_seq = encoded.transform(seq.reshape(-1, 1)).toarray().reshape(1,-1)\n",
    "    except ValueError:\n",
    "        print(\"loose\", fn)\n",
    "        continue\n",
    "        \n",
    "    #print(len(encoded_seq), encoded_seq.shape)\n",
    "    label = np.zeros(Nmax*20)\n",
    "    label[:len(seq)*20] = encoded_seq\n",
    "    \n",
    "    res_ids = np.unique(prot.resid)\n",
    "    for i in res_ids:\n",
    "        if(i>=0):\n",
    "            prot.mutateResidue('resid ' + str(i), 'GLY')\n",
    "\n",
    "        \n",
    "    \n",
    "    coo = prot.get('coords')\n",
    "    c = np.mean(coo, axis=0)\n",
    "    prot.moveBy(-c)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        prot = prepareProteinForAtomtyping(prot,  verbose=False)\n",
    "    except RuntimeError:\n",
    "        print(\"loose\", fn)\n",
    "        continue\n",
    "    except ValueError:\n",
    "        print(\"less bounds\", fn)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "    prot.filter(\"protein or ions\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        prot_vox, prot_centers, prot_N = getVoxelDescriptors(prot, boxsize=[30,30,30], center=[0,0,0])\n",
    "    except ValueError:\n",
    "        print(\"less bounds\", fn)\n",
    " \n",
    "    prot_vox_t = prot_vox.transpose().reshape([ nchannels, prot_N[0], prot_N[1], prot_N[2]])\n",
    "    \n",
    "    \n",
    "    \n",
    "    X.append(prot_vox_t)\n",
    "    Y.append(label)\n",
    "    \n",
    "    print(prot_vox.shape, prot_N)\n",
    "    #print(prot_vox.shape, prot_N)\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(nchannels, 20, 5)  # (in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = nn.Conv3d(20, 20, 4)\n",
    "        self.conv3 = nn.AvgPool3d(3)  #Conv3d(20, 20, 5)\n",
    "        self.conv4 = nn.Conv3d(20, 25, 4) \n",
    "        self.conv5 = nn.Conv3d(25, 20*Nmax, 4) \n",
    "        self.ff1 = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2= F.relu(self.conv2(x1))\n",
    "        x3 = self.conv3(x2)\n",
    "        x4 = self.conv4(x3)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.ff1(x5)\n",
    "        \n",
    "        return F.sigmoid(x6)\n",
    "        #return F.relu(self.conv4(x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(X) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prots_x = torch.tensor( X )\n",
    "tensor_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split( tensor_x, tensor_y, test_size = 0.1)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "results = model.forward(tensor_x)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = Model()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    " \n",
    "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
    " \n",
    "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
    " \n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    " \n",
    "    output_train = model(x_train)\n",
    "    output_val = model(x_val)\n",
    "    #print(output_train.shape, output_val.shape, y_train.shape)\n",
    "    # computing the training and validation loss\n",
    "    #y_train = y_train.squeeze()\n",
    "    loss_train = criterion(output_train.reshape(-1)  , y_train.reshape(-1)  )\n",
    "    loss_val = criterion(output_val, y_val)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "     \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    #if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        #print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "n_epochs = 25\n",
    " \n",
    "train_losses = []\n",
    " \n",
    "val_losses = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
